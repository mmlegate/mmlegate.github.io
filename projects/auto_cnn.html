<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Jacquard+12+Charted&family=Karla&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha512-SnH5WK+bZxgPHs44uWIX+LLJAJ9/2PkPKZ5QiAj6Ta86w+fsb2TkcmfRyVX3pBnMFcV7oQPJkl9QevSCWr3W6A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    <link rel="stylesheet" href="projects.css">

    <script defer src="https://pyscript.net/alpha/pyscript.js"></script>

    <title>CNN Autoencoder Project</title>
</head>

<body>
    <!-- NAV BAR -->
    <nav>
        <div class="left">
            <a href="/">Madeline Legate</a>
        </div>
        <div class="right">
            <a href="http://github.com/mmlegate" target="_blank" rel="noopener no-referrer">
                <i class="fa-brands fa-square-github"></i>
                <span>Github</span>
            </a>

            <a href="http://linkedin.com/in/madeline-legate-8405801a6/" target="_blank" rel="noopener no-referrer">
                <i class="fa-brands fa-linkedin"></i>
                <span>Linkedin</span>
            </a>

            <a href="mailto:legate.madeline@gmail.com" >
                <i class="fa-solid fa-square-envelope"></i>
                <span>Email</span>
            </a>
        </div>
    </nav>

    <!-- INTRODUCTION -->
    <section class="intro-section">
        <div class="text"> <h2>Generating Images from Stellar Spectra</h2>
            <p>The Sloan Digital Sky Survey (SDSS) utilizes a 2.5-meter telescope at the Apache Point Observatory in New Mexico to collect stellar data. Its primary objective is to map the universe in unprecedented detail, capturing high-resolution images and spectra of millions of celestial objects across a significant portion of the sky. </p>
            <p>I wanted to use each stellar object's spectra paired with its image to train a neural network to generate images as they might appear on a telescope.</p>
            <div class="links">
                <a href="#tools">
                    <i class="fa-solid fa-tools"></i>
                    <span>Tools</span>
                </a>

                <a href="#result">
                    <i class="fa-solid fa-gift"></i>
                    <span>Result</span>
                </a>

                <a href="#code">
                    <i class="fa-solid fa-code"></i>
                    <span>Code</span>
                </a>
            </div>
        </div> 
        <div class="headshot">
            <img src="/../images/torus_variations2.webp">
        </div>
    </section>

    <!-- TOOLS -->
    <section id="tools" class="tools-section"> <h2>Tools</h2>
        <div class="tab-wrap">

            <!-- active tab on page load gets checked attribute -->
            <input type="radio" id="tab1" name="tabGroup1" class="tab" checked>
            <label for="tab1"><img src="/../images/python_logo.webp" alt="Service Now logo"></label>
        
            <input type="radio" id="tab2" name="tabGroup1" class="tab">
            <label for="tab2"><img src="/../images/pytorch_logo.webp" alt="Python logo"></label>
        
            <input type="radio" id="tab3" name="tabGroup1" class="tab">
            <label for="tab3"><img src="/../images/colab_logo.webp" alt="Power BI logo"></label>
        
            <div class="tab__content">
                <h4>Python</h4>
                <i>Python is a versatile programming language, widely used in web development, data science, AI, and automation, supported by a rich ecosystem of libraries and frameworks.</i>
                <br>
                <br>
                <ul>
                    <li>SDSS contains stellar object spectra and its image, but not in a format that can be easily obtained in large numbers. Python was used to perform an API call to the SDSS website, retrieving thousands of 64 x 64 images.</li>
                    <li>The data was preprocessed and portioned for training, validation, and test in Python. I decided to use a portioning of 80 - 10 - 10 on 10,000 sets of image/spectra pairs.</li>
                    <li>The images from SDSS are originally in binary, so I implemented some quick functions to transform them into RGB matrices. This permitted easy in-cell viewing in Colab.</li>
                </ul>
            </div>
        
            <div class="tab__content">
                <h4>Pytorch</h4>
                <i>PyTorch is an open-source machine learning library designed for deep learning and neural network tasks, offering dynamic computational graphs and seamless integration with Python.</i>
                <br>
                <br>
                <ul>
                    <li>The course associated with this project, Neural Network Methods in Physics, was centered around Pytorch for implementing deep learning techniques.</li>
                    <li>A convolutional autoencoder is ideal for this project because it effectively captures and reconstructs the spatial and spectral features of astronomical images and spectra.</li>
                    <li>I only applied 1D convolutional layers, effectively reconstructing the 1D input array of 8 spectral values into a 1 x (64 x 64) array of RGB values. This allowed me to reshape the output into its proper RGB matrix format for viewing. </li>
                    <li>For the results below, we used 10,000 sets of 8 spectral values  and a batchsize of 10. We scaled output channels 2X at each convolution with a fully connected layer of size 256.</li>
                </ul>
            </div>
        
            <div class="tab__content">
                <h4>Google Colab</h4>
                <i>Google Colab is a cloud-based Jupyter notebook environment that allows you to write, execute, and share code, while also using free GPU and TPU resources for machine learning and data analysis tasks.</i>
                <br>
                <br>
                <ul>
                    <li>To organize the final project of this course, I used Google Colab. It was most appropriate due to its integration with Google Drive, as I configured the API call to automatically download each file in Drive.</li>
                    <li>The end result is a concise report containing a convolutional autoencoder of accuracy 85%. The steps to using the convolutional autoencoder is clearly discretized for easy following.</li>
                </ul>
            </div>
        
          </div>
    </section>

    <!-- RESULT -->
    <section id="result" class="result-section"> <h2>Result</h2>
        <div class="data">
            <img src="/../images/auto_cnn_data.webp" alt="Image data from SDSS">
            <p>The dataset that we used to pull images from SDSS is located on <a href="https://www.kaggle.com/datasets/fedesoriano/stellar-classification-dataset-sdss17">Kaggle</a>. There are three classes for the stellar objects, pictured right: galaxy, quasar, and star. 
            <br>
            <br>
            The neural network performs best when training on only one class. The results below showcase only galaxies with an accuracy of about 85% using the SSIM index.</p>
        </div>
        <p>Below is the best/worst results on the testing dataset. Left, we see that the highest accuracy is 97%, and right, we see the lowest accuracy of 17%.</p>
        <div class="comparison">
            <img src="/../images/auto_cnn_best.webp" alt="Comparison of neural network output and source image">
            <img src="/../images/auto_cnn_worst.webp" alt="Comparison of neural network output and source image">
        </div>
        <p>In order to determine which datapoints were confusing the neural network, we generated a pairplot of the spectral data, where each point is shaded with the SSIM index. The more purple the datapoint, the worse the neural network performed.
        <br>
        <br>
        We see that each component of the spectral data is positively related to another. The neural network performs best closer to the origin, where the linear relationship is most clearly defined. As we move away from the origin, there is more uncertainty that the neural network must account for.</p>
        <img src="/../images/auto_cnn_pairplot.webp" alt="Pairplot of spectral data">
    </section>

    <!-- CODE -->
    <section id="code" class="code-section">
        <div class="text"> <h2> Source Code:</h2>
            <a href="https://github.com/mmlegate/mmlegate.github.io/tree/main/projects"><pre><code class="python">class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
            
        # Encoder part of the autoencoder: output channels scale 2X at each convolution, ReLU activation and Max Pooling between each layer
        self.encoder = nn.Sequential(
            nn.Conv1d(in_channels=num_features, out_channels=32, kernel_size=3, padding=1), # 1st Conv layer: input to 32 channels
            nn.ReLU(), # Activation function
            nn.MaxPool1d(kernel_size=2, stride=2, padding=1), # Downsampling by max pooling </code></pre></a>

        </div> 
        <div class="headshot">
            <img src="/../images/torus background.webp">
        </div>
    </section>

</body>